<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta http-equiv="x-ua-compatible" content="ie=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <title>Ryokou - 2020-08-20-linear-algebra</title>
        <link rel="stylesheet" href="../../web/static/main.css" />
        <script src="../../web/static/main.bundle.js"></script>
        <style>
            header {
                width: 100%;
            }
            nav {
                width: 100%;
            }

            header nav {
                display: flex;
                justify-content: space-between;
            }

            footer {
                width: 100%;
                text-align: center;
            }
        </style>
    </head>

    <body>
        <header>
            <nav>
                <a href="../../">Home</a>
                <a href="../../about.html">About</a>
                <a href="../../contact.html">Contact</a>
                <a href="../../archive.html">Archive</a>
            </nav>
        </header>

        <style>
    /* main {
        display: flex;
        flex-direction: column;
        align-items: center;
    }

    article {
        max-width: 680px;
    } */
</style>

<main role="main">
    <h1>2020-08-20-linear-algebra</h1>
    <article>
        <!-- <section class="header"></section> -->
        <section><p><span class="math inline"><em>C</em> = <em>A</em><em>B</em></span></p>
<p>If <span class="math inline"><em>B</em></span> is seen as a sequence of columns <span class="math inline"><em>b</em><sub>1</sub>, <em>b</em><sub>2</sub>, ⋯, <em>b</em><sub><em>n</em></sub></span>, then <span class="math inline"><em>C</em></span> can be seen as a sequence of columns <span class="math inline"><em>c</em><sub>1</sub>, <em>c</em><sub>2</sub>, ⋯, <em>c</em><sub><em>n</em></sub></span> where <span class="math inline"><em>c</em><sub><em>i</em></sub> = <em>A</em><em>b</em><sub><em>i</em></sub></span> only relates to the corresponding column <span class="math inline"><em>b</em><sub><em>i</em></sub></span> in <span class="math inline"><em>B</em></span></p>
<p>If <span class="math inline"><em>A</em></span> is seen as a sequence of rows <span class="math inline"><em>a</em><sub>1</sub>, <em>a</em><sub>2</sub>, ⋯, <em>a</em><sub><em>n</em></sub></span>, then <span class="math inline"><em>C</em></span> can be seen as a sequence of row <span class="math inline"><em>c</em><sub><em>i</em></sub>, <em>c</em><sub>2</sub>, ⋯, <em>c</em><sub><em>n</em></sub></span> where <span class="math inline"><em>c</em><sub><em>i</em></sub> = <em>a</em><sub><em>i</em></sub><em>B</em></span> only relates to the corresponding row <span class="math inline"><em>a</em><sub><em>i</em></sub></span> in <span class="math inline"><em>A</em></span></p>
<hr />
<p>2 vectors are orthogonal iff <span class="math inline"><em>x</em><sup><em>T</em></sup><em>y</em> = <em>y</em><sup><em>T</em></sup><em>x</em> = 0</span></p>
<p>    <span class="math inline"><em>x</em><sup><em>T</em></sup><em>x</em> = 0</span> iff <span class="math inline"><em>x</em> = 0</span></p>
<p>2 subspaces <span class="math inline"><em>S</em></span> and <span class="math inline"><em>T</em></span> are orthogonal iff all <span class="math inline"><em>x</em> ∈ <em>S</em></span> and <span class="math inline"><em>y</em> ∈ <em>T</em></span> are orthogonal</p>
<hr />
<p>一组正交的非 0 向量 <span class="math inline"><em>a</em><sub>1</sub>, <em>a</em><sub>2</sub>, ⋯, <em>a</em><sub><em>n</em></sub></span> 一定是线性无关的</p>
<p>    假设这组向量是线性相关的，则存在一组不全为0的系数系数 <span class="math inline"><em>x</em><sub><em>i</em></sub></span> 使得 <span class="math inline">$x_1a_1 + x_2a_2 + \dotsc + x_na_n = 0$</span>。</p>
<p>    等式两边同时乘以 <span class="math inline"><em>x</em><sub>1</sub><sup><em>T</em></sup></span> 得到 <span class="math inline"><em>x</em><sub>1</sub><sup><em>T</em></sup><em>x</em><sub>1</sub><em>a</em><sub>1</sub> = 0</span> 则 <span class="math inline"><em>a</em><sub>1</sub> = 0</span>，用同样的方法可以得到 <span class="math inline">∀<em>i</em>, <em>a</em><sub><em>i</em></sub> = 0</span>，与题设产生矛盾。</p>
<hr />
<p>NullSpace is perpendicular to RowSpace</p>
<p>    <span class="math inline"><em>A</em><em>x</em> = 0</span> and <span class="math inline"><em>A</em></span> can be seen as a sequence of row vectors. All these row vector dot-products x equal to 0. So All vectors in RowSpace are orthogonal to vectors in NullSpace.</p>
<p>For the same reason, LeftNullSpace is perpendicular to ColSpace</p>
<p>NullSpace and RowSpace are Complementary in <span class="math inline"><em>R</em><sup><em>n</em></sup></span></p>
<p>    NullSpace is spanned by <span class="math inline"><em>n</em> − <em>r</em><em>a</em><em>n</em><em>k</em>(<em>A</em>)</span> independent vectors</p>
<p>    RowSpace is spanned by <span class="math inline"><em>r</em><em>a</em><em>n</em><em>k</em>(<em>A</em>)</span> independent vectors</p>
<p>    Since <span class="math inline"><em>x</em><sup><em>T</em></sup><em>x</em> = 0</span> iff <span class="math inline"><em>x</em> = 0</span>, we know that, the intersection of two spaces is <span class="math inline">0</span></p>
<p>    So (NullSpace + RowSpace) is spanned by <span class="math inline"><em>n</em> − <em>r</em><em>a</em><em>n</em><em>k</em>(<em>A</em>) + <em>r</em><em>a</em><em>n</em><em>k</em>(<em>A</em>)</span> independent vectors. Whici means that (NullSpace + RowSpace) = <span class="math inline"><em>R</em><sup><em>n</em></sup></span></p>
<p>For the same reason, LeftNullSpace and ColSpace are Complementary</p>
<p>So we say</p>
<p>    <strong>NullSpace and RowSpace are orthogonal Complementary in <span class="math inline"><em>R</em><sup><em>n</em></sup></span></strong></p>
<p>    <strong>LeftNullSpace and ColSpace are orthogonal Complementary in <span class="math inline"><em>R</em><sup><em>m</em></sup></span></strong></p>
<hr />
<p>3 fundamental theorems of algebra</p>
<ul>
<li>Dimensions of the 4 subspaces</li>
<li>Those spaces come in orthogonal pairs</li>
<li>The orthogonal base for these subspaces`</li>
</ul>
<hr />
<p><span class="math inline"><em>r</em><em>a</em><em>n</em><em>k</em>(<em>A</em><sup><em>T</em></sup><em>A</em>) = <em>r</em><em>a</em><em>n</em><em>k</em>(<em>A</em>)</span></p>
<p>Proof: Since KernalSpace and RowSpace are orthogonal complement to each other, if we can prove <span class="math inline"><em>A</em><sup><em>T</em></sup><em>A</em></span> and <span class="math inline"><em>A</em></span> have equal KernalSpace, then we can prove that <span class="math inline"><em>r</em><em>a</em><em>n</em><em>k</em>(<em>A</em><sup><em>T</em></sup><em>A</em>) = <em>r</em><em>a</em><em>n</em><em>k</em>(<em>A</em>)</span></p>
<p>Part 1. <span class="math inline"><em>A</em><em>x</em> = 0 ⇒ <em>A</em><sup><em>T</em></sup><em>A</em><em>x</em> = 0</span></p>
<p>Part 2. <span class="math inline"><em>A</em><sup><em>T</em></sup><em>x</em> = 0 ⇒ <em>x</em><sup><em>T</em></sup><em>A</em><sup><em>T</em></sup><em>A</em><em>x</em> = 0 ⇒ (<em>A</em><em>x</em>)<sup><em>T</em></sup><em>A</em><em>x</em> = 0</span></p>
<p>    Because <span class="math inline"><em>x</em><sup><em>T</em></sup><em>x</em> = 0</span> iff <span class="math inline"><em>x</em> = 0</span> we know that <span class="math inline"><em>A</em><em>x</em> = 0</span></p>
<p>So from two parts above, <span class="math inline"><em>K</em><em>e</em><em>r</em>(<em>A</em><sup><em>T</em></sup><em>A</em>) = <em>K</em><em>e</em><em>r</em>(<em>A</em>)</span> which means <span class="math inline"><em>r</em><em>a</em><em>n</em><em>k</em>(<em>A</em><sup><em>T</em></sup><em>A</em>) = <em>r</em><em>a</em><em>n</em><em>k</em>(<em>A</em>)</span></p>
<p>From above proof we can know that <strong><span class="math inline"><em>A</em><sup><em>T</em></sup><em>A</em></span> is invertible iff <span class="math inline"><em>r</em><em>a</em><em>n</em><em>k</em>(<em>A</em>) = <em>n</em></span> in other words, A has independent columns</strong></p>
<hr />
<p><strong>Fredholm’s Alternative?</strong></p>
<hr />
<p>Projection Matrix: If we are to project 1 vector <span class="math inline"><em>b</em></span> to a subspace <span class="math inline"><em>S</em></span>, we need to find the projected vector <span class="math inline"><em>p</em></span>.</p>
<p><span class="math inline"><em>P</em><em>b</em> = <em>p</em></span></p>
<p><span class="math inline"><em>S</em></span> is spanned by vectors <span class="math inline">{<em>a</em><sub>1</sub>, <em>a</em><sub>2</sub>, ⋯, <em>a</em><sub><em>n</em></sub>}</span>, so it can be seen as the ColSpace of a matrix <span class="math inline"><em>A</em></span> whose columns are basises of <span class="math inline"><em>S</em></span>, so <span class="math inline"><em>p</em></span> can be written as <span class="math inline"><em>x</em><sub>1</sub><em>a</em><sub>1</sub> + <em>x</em><sub>2</sub><em>a</em><sub>2</sub> + ⋯ + <em>x</em><sub><em>n</em></sub><em>a</em><sub><em>n</em></sub> = <em>A</em><em>x</em></span></p>
<p><span class="math inline"><em>b</em> − <em>p</em></span> should be perpendicular to all vectors inside ColSpace(A), which means</p>
<p><span class="math inline">∀<em>i</em>, <em>a</em><sub><em>i</em></sub><sup><em>T</em></sup> ⋅ (<em>p</em> − <em>b</em>) = 0</span> which can also be written as <span class="math inline"><em>A</em><sup><em>T</em></sup>(<em>p</em> − <em>b</em>) = <em>A</em><sup><em>T</em></sup>(<em>A</em><em>x</em> − <em>b</em>) = 0</span></p>
<p>By solving this equation we can get <span class="math inline"><em>x</em> = (<em>A</em><sup><em>T</em></sup><em>A</em>)<sup> − 1</sup><em>A</em><sup><em>T</em></sup><em>b</em></span>, then <span class="math inline"><em>P</em><em>b</em> = <em>A</em><em>x</em> = <em>A</em>(<em>A</em><sup><em>T</em></sup><em>A</em>)<sup> − 1</sup><em>A</em><sup><em>T</em></sup><em>b</em> ⇒ <em>P</em> = <em>A</em>(<em>A</em><sup><em>T</em></sup><em>A</em>)<sup> − 1</sup><em>A</em><sup><em>T</em></sup></span></p>
<p>So <span class="math inline"><em>P</em> = <em>A</em>(<em>A</em><sup><em>T</em></sup><em>A</em>)<sup> − 1</sup><em>A</em><sup><em>T</em></sup></span> is the projection matrix that maps a vector onto ColSpace(A)</p>
<p>左零空间和列空间是正交补，所以空间中的每一个向量 <span class="math inline"><em>e</em></span> 都可以分解为 <span class="math inline"><em>e</em> = <em>u</em> + <em>v</em></span> 其中 <span class="math inline"><em>u</em></span> 是列空间的向量，<span class="math inline"><em>v</em></span> 是左零空间的向量</p>
<p><br /><span class="math display">$$
u = Pe \\
u = e - u = e - Pe = (I- P)e
$$</span><br /></p>
<p>So <span class="math inline"><em>I</em> − <em>P</em></span> is the projection matrix that maps a vector onto LeftNull(A)</p>
<p>It’s easy to verify by calculation that, if <span class="math inline"><em>P</em></span> is a projection matrix then <span class="math inline"><em>P</em><sup>2</sup> = <em>P</em></span> and <span class="math inline"><em>P</em><sup><em>T</em></sup> = <em>P</em></span></p>
<hr />
<p>Least Square Method</p>
<p>For an inconsistent equation <span class="math inline"><em>A</em><em>x</em> = <em>b</em></span>，it has no solution, so we may want to find such a solution that makes the distance between <span class="math inline"><em>A</em><em>x</em></span> and <span class="math inline"><em>b</em></span> be minimum. Such <span class="math inline"><em>A</em><em>x</em></span> must be the projection vector from <span class="math inline"><em>b</em></span> to ColSpan(A) because <span class="math inline"><em>A</em><em>x</em></span> can be any vector inside ColSpan(A).</p>
<p><span class="math inline"><em>A</em><sup><em>T</em></sup>(<em>b</em> − <em>A</em><em>X</em>) = 0 ⇒ <em>A</em><sup><em>T</em></sup><em>A</em><em>x</em> = <em>A</em><sup><em>T</em></sup><em>b</em></span></p>
<p>So instead of solving <span class="math inline"><em>A</em><em>x</em> = <em>b</em></span>, we just need to solve <span class="math inline"><em>A</em><sup><em>T</em></sup><em>A</em><em>x</em> = <em>A</em><sup><em>T</em></sup><em>b</em></span> which must have at least one solution.</p>
<p><span class="math inline"><em>A</em><sup><em>T</em></sup><em>A</em><em>x</em> = <em>A</em><sup><em>T</em></sup><em>b</em></span> can be seen as a translate of the solution set of the homogeneous equation <span class="math inline"><em>A</em><sup><em>T</em></sup><em>A</em><em>x</em> = 0</span>.</p>
<p>Since <span class="math inline"><em>A</em><sup><em>T</em></sup><em>A</em></span> is a square matrix, then if <span class="math inline"><em>A</em><sup><em>T</em></sup><em>A</em></span> is invertible (which means <span class="math inline"><em>A</em></span> has independent columns), the equation has a unique solution.</p>
<p>The equation can have multiple solutions.</p>
<p>Best fit</p>
<p>我们可能拿到一些有误差的数据，使得我们的方程没有解，比如我们拿到三个点 <span class="math inline">(0, 6), (1, 0)(2, 0)</span> 因为某些测量什么的原因，他们并不在一条直线上，所以我们的方程 <span class="math inline"><em>y</em> = <em>M</em><em>x</em> + <em>B</em></span> 无解。可以写成矩阵形式:</p>
<p><br /><span class="math display">$$
A=\left(\begin{array}{ll}
0 &amp; 1 \\
1 &amp; 1 \\
2 &amp; 1
\end{array}\right) \quad x=\left(\begin{array}{c}
M \\
B
\end{array}\right) \quad b=\left(\begin{array}{l}
6 \\
0 \\
0
\end{array}\right)
$$</span><br /></p>
<p>使用最小二乘法可以找到一个 <span class="math inline"><em>x</em></span> 使得 <span class="math inline"><em>A</em><em>x</em></span> 与 <span class="math inline"><em>b</em></span> 最近，即 <span class="math inline">||<em>A</em><em>x</em> − <em>b</em>||<sup>2</sup></span> 最小。 Every entries of Ax is one value of the resulting function</p>
<p><br /><span class="math display">$$
A\left(\begin{array}{c}
-3 \\
5
\end{array}\right)=\left(\begin{array}{c}
-3(0)+5 \\
-3(1)+5 \\
-3(2)+5
\end{array}\right)=\left(\begin{array}{c}
f(0) \\
f(1) \\
f(2)
\end{array}\right)
$$</span><br /></p>
<p>即<span class="math inline">||<em>b</em> − <em>A</em><em>x</em>||<sup>2</sup> = (6 − <em>y</em>(0))<sup>2</sup> + (0 − <em>y</em>(1))<sup>2</sup> + (0 − <em>y</em>(2))<sup>2</sup></span> 最小，即最小二乘法得到的解使得在 y 轴上距离平方和最小</p>
<p>通过上面的例子我们可以看出来，Ax的每一项其实都和我们求得的系数后的样子无关， 也就是说 对于 <span class="math inline"><em>y</em> = <em>B</em><sub>1</sub><em>g</em><sub>1</sub>(<em>x</em>) + <em>B</em><sub>2</sub><em>g</em><sub>2</sub>(<em>x</em>) + ⋯ + <em>B</em><sub><em>m</em></sub><em>g</em><sub><em>m</em></sub>(<em>x</em>)</span> 这样的函数，我们同样可以使用最小二乘法得到一个近似解。因为同样的理由，该解同样是使 y 轴上距离平方和最小的解</p>
<p>基于同样的理由，我们可以更进一步，我们可以使用最小二乘法来得到椭圆图像的一个近似解。 The general equation for an ellipse (actually, for a nondegenerate conic section) is <span class="math inline"><em>x</em><sup>2</sup> + <em>B</em><em>y</em><sup>2</sup> + <em>C</em><em>x</em><em>y</em> + <em>D</em><em>x</em> + <em>E</em><em>y</em> + <em>F</em> = 0</span> 此时可以看作 <span class="math inline"><em>z</em> = <em>f</em>(<em>x</em>, <em>y</em>) = <em>x</em><sup>2</sup> + <em>B</em><em>y</em><sup>2</sup> + <em>C</em><em>x</em><em>y</em> + <em>D</em><em>x</em> + <em>E</em><em>y</em></span>，我们的每个数据点 <span class="math inline">(<em>x</em><sub>0</sub>, <em>y</em><sub>0</sub>)</span> 可以升维后看作 <span class="math inline">(<em>x</em><sub>0</sub>, <em>y</em><sub>0</sub>, <em>z</em> = 0)</span>。得到矩阵</p>
<p><br /><span class="math display">$$A=\left(\begin{array}{rrrrr}
4 &amp; 0 &amp; 0 &amp; 2 &amp; 1 \\
1 &amp; 2 &amp; 2 &amp; 1 &amp; 1 \\
1 &amp; -1 &amp; 1 &amp; -1 &amp; 1 \\
4 &amp; 2 &amp; -1 &amp; -2 &amp; 1 \\
1 &amp; -3 &amp; -3 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; -1 &amp; -1 &amp; 1
\end{array}\right) \quad x=\left(\begin{array}{c}
B \\
C \\
D \\
E \\
F
\end{array}\right) \quad b=\left(\begin{array}{r}
0 \\
-4 \\
-1 \\
-1 \\
-9 \\
-1
\end{array}\right)$$</span><br /></p>
<p>我们可以使用最小二乘法得到一个到在 z 轴上距离平方和最小的解 (数据点和 a nondegenerate conic section 图像在 z 轴上距离平方和最小的解</p></section>
    </article>
</main>

    </body>
</html>
