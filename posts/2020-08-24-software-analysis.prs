Analyze a program to reason about its behaviors and determine whether it satisfies some properties 

:h3 Sound & Complete

**Sound**: over-approximation
**Complete**: under-approximation
- e.g. 某个程序有 10 个指针错误，一个 Sound 的分析可能得出除了真实的那 10 个错误外还有其他错误，一个 Complete 的分析可能得出在那 10 个错误中的 2 个错误

- ```
+------------------------------+
|                              |
|        +---------------------+
|        |                     |
|        |         +-----------+
|        |         |           |
| Sound  |  Truth  |  Complete |
|        |         |           |
+--------+---------+-----------+
```

Rice Theorem tells us that we cannot build an analyzer thats both **sound** and **complete**

Two options:
- - Compromise Soundness: 造成漏报
- - Compromise Completeness: 造成误报

Most of the time we prefer compromising completeness. 

Static Analysis ensure (or get close to) Soundness while making good trade offs between precision and speed.

:h3 Static Analysis

Static Analysis = Abstraction + over-approximation
- e.g. 例如分析程序中变量的符号
-- - Abstraction: 
--- ```
Concrete Domain         Abstract Domain
    v = 100                 P
    v = - 1                 N 
    v = 0                   O
    v = e ? 1 : -1          T (unknown)
```
-- - over-approximation: Transfer function
--- defines how to evaluate different program statements on abstract values
---- e.g. 
---- ```
P + P = P
P + N = T
```


:h3 IR

:h4 Ast vs IR

Ast: 
- - high level and close to grammar structure
- - usually language dependent 
- - lack of control flow information
- - suitable for fast type checking 

IR:
- - low level and closed to machine code
- - usually language independent
- - contains control flow information

IR is usually considered as the basis for static analysis.

:h4 3-addr-code 

omitted.

:h4 Static Single Assignment

All assignments in SSA are to variables with distinct names

:br

What if a variable use is at control flow merges?
- ```
if a = 1                if a = 1 
then x_0 = 1            then x_0 = 1
else x_1 = 2            else x_1 = 2
y = x + 7        =>     x = phi(x_0, x_1)
                        y = x + 7
```
A special merge operator $\phi$, (called phi-function), is introduced to select the values at merge nodes
$\phi(x_0, x_1)$ has the value $x_0$ if the control flow passes through the true part of the conditional and the value $x_1$ otherwise

:h5 Advantages & Disadvantages

Advantages of SSA:
- Flow information is indirectly incorporated into the unique variable names
-- (even flow-insensitive analysis gains partial precision of flow-sensitive analysis via SSA
- Define-and-Use pairs are explicit
-- Enable more effective data facts storage and propagation in some on-demand tasks
-- Some optimization tasks perform better on SSA (e.g. conditional constant propagation, global value numbering

Disadvantages of SSA: 
- May introduce too many variables and phi-functions
- May introduce inefficiency problem when translating to machine code (due to copy operations)

:h3 Control Flow Analysis
Usually refer to building Control Flow Graph (CFG)
- CFG serves as the basic structure for static analysis. The node in CFG is a Basic Block (BB). 

**Basic blocks (BB)** are maximal sequences of consecutive three-address instructions with the properties that
- It can be entered only at the beginning
- It can be exited only at the end

**How to build Basic Blocks?**
INPUT: A sequence of three-address instructions 
OUTPUT: A list of basic blocks of P
Steps: 
- 1. Determine the leaders in P
-- - The first instruction in P is a leader
-- - Any target instruction of a conditional or unconditional jump is a leader
-- - Any instruction that immediately follows a conditional or unconditional jump is a leader
- 2. Build BBs for P
-- - A BB consists of a leader and all its subsequent instructions until the next leader

**How to build CFG on top of BBs?**
- The nodes of CFG are basic blocks. Usually we add two nodes, Entry and Exit. (They do not correspond to executable IR
- There is an edge from block A to block B if and only if
-- - There is a conditional or unconditional jump from the end of A to the beginning of B
-- - B immediately follows A in the original order of instructions



may analysis: outputs information that may be true (over-approximation)
must analysis: outputs information that must be true (under-approximation)


Input and Output States
Each execution of an IR statement transforms an input state to a new output state
The input (output) state is associated with the program point before (after) the statement

In each data-flow analysis application, we associate with every program point a data-flow value that represents an abstraction of the set of all possible program states that can be observed for that point.

Data-flow analysis is to find a solution to a set of safe-approximation directed constraints on the IN[s]’s and OUT[s]’s, for all statements s.
- - constraints based on semantics of statements (transfer functions)
- - constraints based on the flows of control

:h3 Forward Analysis & Backward Analysis

omitted


:h3 Reaching Definitions Analysis

Definition: A definition `d` at program point `p` reaches a point `q` if there is a path from `p` to `q` such that `d` is not “killed” along that path

:img(src="./reaching-definition.png", height="120")

Reaching definitions can be used to detect possible undefined variables.
- e.g. introduce a dummy definition for each variable v at the entry of CFG, and if the dummy definition of v reaches a point p where v is used, then v may be used before definition (as undefined reaches v)

abstraction: definitions can be represented by bit vectors
- `e.g., D1, D2, D3, D4, ..., D100 (100 definitions)`
transfer function: 
```
D: v = x op y
```
This statement 
- - "generates" a definition D of variable v
- - "kills" all the other definitions in the program that define variable v.
`OUT[B] = genB U (IN[B] - killB)`

A definition reaches a program point as long as there exists at least one path along which the definition reaches.
$IN [B]=\bigcup_{P \text { predecessors of } B}$ OUT $[P]$

```
output[entry] = empty
for block of all_other_blocks:
    output[block] = empty 

while changes to any output:
    for block of all_blocks:
        input = merge output of predecessors
        output[block] = gen(block) <> (input[block] - kill(block))
```

Why this iterative can finally algorithm stop? 
`output[block] = gen(block) <> (input[block] - kill(block))` every part of this statement except input[block] is constant. 
When a fact is added to `output[block]`, whether it's from `gen(block)` or survived from `input[block] - kill(block)`, it stays there forever

Thus output never shrinks.

As the set of facts is finite (e.g., all definitions in the program), there must exist a pass of iteration during which nothing is added to any OUT, and then the algorithm terminates

:h3 Live Variables Analysis

Live variables analysis tells whether the value of variable v at program point p could be used along some path in CFG starting at p. If so, v is live at p; otherwise, v is dead at p.

:img(src="./live-variable.png", height="120")

Information of live variables can be used for register allocations. e.g., at some point all registers are full and we need to use one, then we should favor using a register with a dead value.



transfer function 
对于一个 `a = x op y` 
x y 确定存活，kill a

backward analysis
input[block] = (output[block] - kills) + uses 

output[block]: It is live coming out of B and is not redefined in B
uses: It is used before redefinition in B
kills: It is redefined in B


:h3 Available Expressions Analysis

An expression x op y is available at program point p if 
- 1. **all paths** from the entry to p **must** pass through the evaluation of x op y
- 2. after the last evaluation of x op y, there is no redefinition of x or y

This definition means at program p, we can replace expression x op y by the result of its last evaluation.

transfer function 
对于一个 `a = x op y` 
- Add to OUT the expression x op y (gen)
- Delete from IN any expression involving variable `a` (kill)


:h3 Foundations

Given a CFG (program) with k nodes, the iterative algorithm updates `output[n]` for every node n in each iteration.

Then we can make a k-tuple: $(output[n_1], output[n_2], \dots, output[n_k])$ as an element of set $\left( V _{1} \times V _{2} \ldots \times V _{ k }\right)$ denoted as $V^k$, to hold the values of the analysis after each iteration.

Then each iteration can be considered as taking an action to map an element of $V^k$ to a new element of $V^k$. Abstracted as a function $F : V ^{ k } \rightarrow V ^{ k }$

Then the algorithm outputs a series of k-tuples iteratively until a k-tuple is the same as the last one in two consecutive iterations.


Data flow analysis can be seen as iteratively applying transfer functions and meet/join operations on the values of a lattice until we reach.

If we guarantee that $F$ is monotonic, then its compromised to terminate, and finally reach the fixed point.

In each iteration, it is equivalent to think that we apply function $F$ which consists of
- 1. transfer function $f_i: L \rightarrow L$ for every node
- 2. join/meet function $\sqcup / \sqcap : L \times L \rightarrow L$ for control-flow confluence


:h3 Meet-Over-All-Paths Solution (MOP)

MOP 和上面讨论的 iterative approach 的区别在于 CFG 中汇聚点的处理方式不同。
以 $S_4$ 为例
- $input[S_4] = f_{s_3}(f_{s_1}(output[entry]) \sqcup f_{s_2}(output[entry]))$
- $mop[S_4] = f_{s_3}(f_{s_1}(output[entry])) \sqcup f_{s_3}(f_{s_2}(output[entry]))$

四舍五入就是 
- - $input = F ( x \sqcup y )$
- - $mop = F ( x ) \sqcup F ( y )$
-- (如果 F 满足分配律的话二者就是相同的

我们可以证明，MOP 有着更高的精度：
- by definition of lub $\sqcup$, we have $x \subseteq x \sqcup y$ and $y \subseteq x \sqcup y$
- as $F$ is monotonic, we have $F ( x ) \sqsubseteq F ( x \sqcup y )$ and $F ( y ) \sqsubseteq F ( x \sqcup y )$, which means $F ( x \sqcup y )$ is a upper bound for $x$ and also for $y$
- thus we have the lub $F(x) \sqcup F(y) \sqsubseteq F ( x \sqcup y )$


:h3 Constant Propagation

